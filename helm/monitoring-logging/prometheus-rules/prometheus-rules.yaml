kind: ConfigMap
apiVersion: v1
metadata:
  name: additional-prometheus-rules
  namespace: flux-system
data:
  additional-rules.yaml: |2-
      additionalPrometheusRulesMap:
          customrules:
            groups:
            - name: PVC
              rules:
              - alert: KubernetesPersistentvolumeclaimPending
                expr: 'kube_persistentvolumeclaim_status_phase{phase="Pending"} == 1'
                for: 2m
                labels:
                  severity: warning
                  type: pvc
                annotations:
                  summary: Kubernetes PersistentVolumeClaim pending (instance {{ $labels.instance }})
                  description: "PersistentVolumeClaim {{ $labels.namespace }}/{{ $labels.persistentvolumeclaim }} is pending\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

              - alert: KubernetesVolumeOutOfDiskSpace(<20%)
                expr: 'kubelet_volume_stats_available_bytes / kubelet_volume_stats_capacity_bytes * 100 < 20'
                for: 2m
                labels:
                  severity: warning
                  type: pvc
                annotations:
                  summary: Kubernetes Volume out of disk space (instance {{ $labels.instance }})
                  description: "Volume is almost full (< 20% left)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

              - alert: KubernetesVolumeOutOfDiskSpace
                expr: 'kubelet_volume_stats_available_bytes / kubelet_volume_stats_capacity_bytes * 100 < 10'
                for: 2m
                labels:
                  severity: crititcal
                  type: pvc
                annotations:
                  summary: Kubernetes Volume out of disk space (instance {{ $labels.instance }})
                  description: "Volume is almost full (< 10% left)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

              - alert: KubernetesVolumeFullInFourDays
                expr: 'predict_linear(kubelet_volume_stats_available_bytes[6h], 4 * 24 * 3600) < 0'
                for: 6h
                labels:
                  severity: critical
                  type: pvc
                annotations:
                  summary: Kubernetes Volume full in four days (instance {{ $labels.instance }})
                  description: "{{ $labels.namespace }}/{{ $labels.persistentvolumeclaim }} is expected to fill up within four days. Currently {{ $value | humanize }}% is available.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"

              - alert: KubernetesPersistentvolumeError
                expr: 'kube_persistentvolume_status_phase{phase=~"Failed|Pending", job="kube-state-metrics"} > 0'
                for: 0m
                labels:
                  severity: critical
                  type: pvc
                annotations:
                  summary: Kubernetes PersistentVolume error (instance {{ $labels.instance }})
                  description: "Persistent volume is in bad state\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
            - name: ApplicationAlerts
              rules:
              - alert: 5xxStatusCodes
                expr: sum(rate(nginx_ingress_controller_requests{controller_pod=~".*",controller_class=~".*",namespace=~".*",status=~"[5].*"}[5m])) > 5
                for: 1m
                labels:
                  severity: critical
                annotations:
                  summary: "5xx status codes detected"
                  description: "5xx status code in the ingress {{ $labels.ingress }} detected."
            - name: NodeExporter
              rules:
              - alert: HostMemoryUnderMemoryPressure
                expr: 'rate(node_vmstat_pgmajfault[1m]) > 1000'
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: Host memory under memory pressure (instance {{ $labels.instance }})
                  description: "The node is under heavy memory pressure. High rate of major page faults\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: HostMemoryIsUnderUtilized
                expr: '100 - (rate(node_memory_MemAvailable_bytes[30m]) / node_memory_MemTotal_bytes * 100) < 20'
                for: 1w
                labels:
                  severity: info
                annotations:
                  summary: Host Memory is under utilized (instance {{ $labels.instance }})
                  description: "Node memory is < 20% for 1 week. Consider reducing memory space.\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: HostUnusualNetworkThroughputIn
                expr: 'sum by (instance) (rate(node_network_receive_bytes_total[2m])) / 1024 / 1024 > 100'
                for: 5m
                labels:
                  severity: warning
                annotations:
                  summary: Host unusual network throughput in (instance {{ $labels.instance }})
                  description: "Host network interfaces are probably receiving too much data (> 100 MB/s)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: HostUnusualNetworkThroughputOut
                expr: 'sum by (instance) (rate(node_network_transmit_bytes_total[2m])) / 1024 / 1024 > 100'
                for: 5m
                labels:
                  severity: warning
                annotations:
                  summary: Host unusual network throughput out (instance {{ $labels.instance }})
                  description: "Host network interfaces are probably sending too much data (> 100 MB/s)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: HostUnusualDiskReadRate
                expr: 'sum by (instance) (rate(node_disk_read_bytes_total[2m])) / 1024 / 1024 > 50'
                for: 5m
                labels:
                  severity: warning
                annotations:
                  summary: Host unusual disk read rate (instance {{ $labels.instance }})
                  description: "Disk is probably reading too much data (> 50 MB/s)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: HostUnusualDiskWriteRate
                expr: 'sum by (instance) (rate(node_disk_written_bytes_total[2m])) / 1024 / 1024 > 50'
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: Host unusual disk write rate (instance {{ $labels.instance }})
                  description: "Disk is probably writing too much data (> 50 MB/s)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: HostOutOfDiskSpace
                expr: '(node_filesystem_avail_bytes * 100) / node_filesystem_size_bytes < 10 and ON (instance, device, mountpoint) node_filesystem_readonly == 0'
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: Host out of disk space (instance {{ $labels.instance }})
                  description: "Disk is almost full (< 10% left)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: HostDiskWillFillIn24Hours
                expr: '(node_filesystem_avail_bytes * 100) / node_filesystem_size_bytes < 10 and ON (instance, device, mountpoint) predict_linear(node_filesystem_avail_bytes{fstype!~"tmpfs"}[1h], 24 * 3600) < 0 and ON (instance, device, mountpoint) node_filesystem_readonly == 0'
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: Host disk will fill in 24 hours (instance {{ $labels.instance }})
                  description: "Filesystem is predicted to run out of space within the next 24 hours at current write rate\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: HostOutOfInodes
                expr: 'node_filesystem_files_free / node_filesystem_files * 100 < 10 and ON (instance, device, mountpoint) node_filesystem_readonly == 0'
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: Host out of inodes (instance {{ $labels.instance }})
                  description: "Disk is almost running out of available inodes (< 10% left)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: HostInodesWillFillIn24Hours
                expr: 'node_filesystem_files_free / node_filesystem_files * 100 < 10 and predict_linear(node_filesystem_files_free[1h], 24 * 3600) < 0 and ON (instance, device, mountpoint) node_filesystem_readonly == 0'
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: Host inodes will fill in 24 hours (instance {{ $labels.instance }})
                  description: "Filesystem is predicted to run out of inodes within the next 24 hours at current write rate\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: HostUnusualDiskReadLatency
                expr: 'rate(node_disk_read_time_seconds_total[1m]) / rate(node_disk_reads_completed_total[1m]) > 0.1 and rate(node_disk_reads_completed_total[1m]) > 0'
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: Host unusual disk read latency (instance {{ $labels.instance }})
                  description: "Disk latency is growing (read operations > 100ms)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: HostUnusualDiskWriteLatency
                expr: 'rate(node_disk_write_time_seconds_total[1m]) / rate(node_disk_writes_completed_total[1m]) > 0.1 and rate(node_disk_writes_completed_total[1m]) > 0'
                for: 2m
                labels:
                  severity: warning
                annotations:
                  summary: Host unusual disk write latency (instance {{ $labels.instance }})
                  description: "Disk latency is growing (write operations > 100ms)\n  VALUE = {{ $value }}\n  LABELS = {{ $labels }}"
              - alert: HostHighCpuLoad
                expr: 'sum by (instance) (avg by (mode, instance) (rate(node_cpu_seconds_total{mode!="idle"}[2m]))) > 0.8'
                for: 0m
                labels:
                  severity: warning


